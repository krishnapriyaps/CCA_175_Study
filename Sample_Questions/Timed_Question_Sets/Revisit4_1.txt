Your spark application required extra Java options as below. -
XX:+PrintGCDetails-XX:+PrintGCTimeStamps
Please replace the XXX values correctly
./bin/spark-submit --name "My app" --master local[4] --conf spark.eventLog.enabled=talse --conf XXX hadoopexam.jar

Q11-----------------------------------------------------
You have been given a database named retail_db with following detail. Which consists 6 tables and datamodel you can see in image.
user=retail_dba 
password=cloudera 
database=retail_db
jdbc URL = jdbc:mysql://quickstart:3306/retail_db
1. Import the entire database in a file format this good for analytical applications on Hadoop e.g. group your data in columns and should be able to query this data using Impala.
Also, while importing to save space you do compression using snappy codec.
2. In impala write the query, which can produce 5 Most popular product categories and save the results in HadoopExam/best_categories.csv in hdfs .
3. In Impala write the query, which can produce top 10 revenue generating products and save the results in HadoopExam/best_products.csv  in hdfs .

Q21-----------------------------------------------------
Problem Scenerio 5: You have been given following data format file. Each datapoint is separated by '|'.
Name|Location1,Location2...Location5|Sex,Age|Father_Name:Number_of_Child
Example Record
Anupam|Delhi,Mumbai,Chennai|Male,45|Daulat:4
Write a Hive DDL script to create a table named "FamilyHead" which should be capable of holding these data. Also note that it should use complex data type e.g. Map, Array,Struct


Problem Scenario 8 : You already have a table name "SAMPLE_07" in a default schema. With following structure.

code string 
description string 
total_emp int 
salary int 

Sample data as below.

sample_07.code sample_07.description sample_07.total_emp sample_07.salary
00-0000 All Occupations 134354250 40690
11-0000 Management occupations 6003930 96150


Create Hive table and data as below.

CREATE TABLE SAMPLE_07
(code string ,
description string ,
total_emp int ,
salary int 
);

INSERT INTO SAMPLE_07 VALUES ('00-0000','All Occupations' ,134354250,40690);
INSERT INTO SAMPLE_07 VALUES ('11-0000','Management occupations' ,6003930,96150);
INSERT INTO SAMPLE_07 VALUES ('02-0000','All Occupations' ,134354250,140690);
INSERT INTO SAMPLE_07 VALUES ('12-0000','Management occupations' ,6003930,99150);
INSERT INTO SAMPLE_07 VALUES ('03-0000','All Occupations' ,134354250,140690);
INSERT INTO SAMPLE_07 VALUES ('13-0000','Management occupations' ,6003930,101150);

Q23-----------------------------------------------------
Problem Scenario 9 : You already have two tables (Hive) name "SAMPLE_07" and "SAMPLE_08" in a default schema. With following structure (both the tables have same structure).

code string 
description string 
total_emp int 
salary int 

Create another table named Employee100K2 in a Family schema, which has all the employees whose salary is >= 100000 from both the tables.
Create required Hive table as below.

CREATE TABLE SAMPLE_08
(code string ,
description string ,
total_emp int ,
salary int 
);

INSERT INTO SAMPLE_08 VALUES ('20-0000','All Occupations' ,134354250,40690);
INSERT INTO SAMPLE_08 VALUES ('11-0000','Management occupations' ,6003930,96150);
INSERT INTO SAMPLE_08 VALUES ('22-0000','All Occupations' ,134354250,140690);
INSERT INTO SAMPLE_08 VALUES ('22-1000','Management occupations' ,6003930,99150);
INSERT INTO SAMPLE_08 VALUES ('23-0000','All Occupations' ,134354250,140690);
INSERT INTO SAMPLE_08 VALUES ('23-1000','Management occupations' ,6003930,101150);

Q24-----------------------------------------------------
Problem Scenario 5 : You have been given following mysql database details.

user=retail_dba 
password=cloudera 
database=retail_db
jdbc URL = jdbc:mysql://quickstart:3306/retail_db

Please accomplish following activities.

1. List all the tables using sqoop command from retail_db
2. Write simple sqoop eval command to check whether you have permission to read database tables or not.
3. Import all the tables as avro files in /user/hive/warehouse/retail_cca174.db
4. Import departments table as a text file in /user/cloudera/departments.




